\chapter{Conclusioni}
L'obiettivo della tesi posto all'inizio della relazione era automatizzare il logging delle interazioni in un ambiente Kubernetes, al fine di identificare le cause principali dei malfunzionamenti nei deployment. In questo documento, si è mostrata una possibile soluzione che non necessita di modificare il codice delle applicazioni. Per quanto riguarda i contributi descritti al Capitolo 1, è stata inizialmente sviluppata una metodologia che, tramite la simbiosi di più componenti, è in grado di fornire il logging delle interazioni, partendo da un file di deployment esistente. Nell'implementazione, è stato poi fornito un programma Python che dimostra come questa configurazione possa essere realizzata automaticamente. Si è poi proceduto alla fase di testing, dove l'implementazione corrente è stata testata con applicazioni di benchmarking esistenti, quali Bookinfo, Chaos Echo, Online Boutique e Sock Shop, simulando multipli tipi di fallimenti.

Allo stadio attuale, sono presenti limitazioni che potrebbero essere affrontate in futuro, sia riguardanti la metodologia, sia riguardanti l'implementazione del prototipo. Parlando della metodologia, è necessaria una sperimentazione più accurata ed estensiva, valutando il comportamento del prototipo su diverse architetture Kubernetes, e con dispiegamenti realmente utilizzati in ambienti di produzione. Questo permetterebbe di validare il prototipo in ambienti reali, dove le variabili e le dinamiche sono molteplici, e potrebbero differire di molto da quelle dei benchmark utilizzati. Inoltre, per quanto concerne la sicurezza, la metodologia proposta presenta alcuni problemi, in particolare per quanto riguarda l'ottenimento dei log. Sarebbe infatti necessario sia un sistema di autenticazione verso l'istanza ElasticSearch, in quanto il servizio attualmente non ne prevede alcuna, rendendo quindi possibile a tutti l'ottenimento dei log se il servizio venisse erroneamente esposto ad Internet. Anche la comunicazione con l'istanza ElasticSearch avviene in chiaro, rendendo non sicuro il trasferimento delle informazioni tramite Internet. Infine, per quanto riguarda l'utilizzo, la soluzione richiede comunque un'attenzione manuale per la parte riguardante l'accesso al pod con l'istanza ElasticSearch, che in un normale ambiente Kubernetes richiede una configurazione manuale sia del punto di Ingress, sia di eventuali firewall in esecuzione sul sistema. Per aggirare questa limitazione, tutta l'elaborazione dello script Python e il post-processing potrebbero essere affrontati in un container Docker in esecuzione sullo stesso namespace, e restituendo su \verb|stdout| direttamente l'output finale di yRCA.

Per quanto riguarda il prototipo, questo potrebbe essere poi ulteriormente esteso con capacità di esportazione del file di output maggiori, come ad esempio la scrittura su un bucket cloud, o l'integrazione con piattaforme di monitoraggio come Grafana\footnote{https://grafana.com} o Prometheus\footnote{https://prometheus.io}. Questo permetterebbe una visualizzazione immediata e interattiva dei dati raccolti, favorendo una diagnosi più rapida e accurata dei problemi riscontrati nelle applicazioni.